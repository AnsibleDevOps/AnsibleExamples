{{ ansible_managed|comment }}

{% if not kafka_cluster %}
broker.id=0
{% elif kafka_cluster %}
{%   for host in groups[kafka_cluster_group] %}
{%     if inventory_hostname == host %}
broker.id={{ loop.index0 }}
{%     endif %}
{%   endfor %}
{% endif %}

delete.topic.enable={{ kafka_enable_topic_deletion|lower }}

# The number of threads that the server uses for receiving requests from the network and sending responses to the network
num.network.threads=3

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=8

# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=102400

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=102400

# The maximum size of a request that the socket server will accept (protection against OOM)
socket.request.max.bytes=104857600

log.dirs={{ kafka_data_dir }}

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=1

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
num.recovery.threads.per.data.dir=1

############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

log.retention.hours={{ kafka_log_retention_hours }}

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
log.segment.bytes=1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

{% if not kafka_zookeeper_cluster %}
zookeeper.connect=localhost:2181
{% elif kafka_zookeeper_cluster %}
zookeeper.connect={{ groups[kafka_zookeeper_cluster_group] | map('extract', hostvars, 'ansible_' ~ kafka_zookeeper_cluster_bind_interface) | map(attribute='ipv4.address') | list | join(':2181,') }}:2181
{% endif %}

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000

group.initial.rebalance.delay.ms=0
